{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GAN use public data\n",
    "assume public data is KITTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import utils\n",
    "import torch\n",
    "from datasets.kitti import KITTIdataset\n",
    "import torchvision\n",
    "from utils import *\n",
    "from torch.nn import BCELoss\n",
    "from torch.autograd import grad\n",
    "import torchvision\n",
    "import torchvision.utils as tvls\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from models.gan import Generator\n",
    "from models.gan import Discriminator\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------Training GAN------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f69dac615f64dc6afb47a00f86b7a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1870.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def freeze(net):\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad_(False) \n",
    "\n",
    "def unfreeze(net):\n",
    "    for p in net.parameters():\n",
    "        p.requires_grad_(True)\n",
    "\n",
    "def gradient_penalty(D ,x, y):\n",
    "    # interpolation\n",
    "    shape = [x.size(0)] + [1] * (x.dim() - 1)\n",
    "    alpha = torch.rand(shape).cuda()\n",
    "    z = x + alpha * (y - x)\n",
    "    z = z.cuda()\n",
    "    z.requires_grad = True\n",
    "\n",
    "    o = D(z)\n",
    "    g = grad(o, z, grad_outputs = torch.ones(o.size()).cuda(), create_graph = True)[0].view(z.size(0), -1)\n",
    "    gp = ((g.norm(p = 2, dim = 1) - 1) ** 2).mean()\n",
    "\n",
    "    return gp\n",
    "run_time = time.strftime(\"%Y-%m-%d_%H-%M-%S\",time.localtime())\n",
    "save_img_dir = f\"gan_result/{run_time}/imgs_kitti_gan\"\n",
    "save_model_dir= f\"gan_result/{run_time}/models_kitti_gan\"\n",
    "save_log_dir = f\"gan_result/{run_time}/log\"\n",
    "\n",
    "os.makedirs(save_model_dir, exist_ok=True)\n",
    "os.makedirs(save_img_dir, exist_ok=True)\n",
    "\n",
    "dataset_name = \"kitti\"\n",
    "\n",
    "\n",
    "os.makedirs(save_log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(save_log_dir)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ###\n",
    "    # hyper params and settings\n",
    "    ###\n",
    "\n",
    "    lr = 2e-4\n",
    "    batch_size = 4\n",
    "    epochs = 20\n",
    "    n_critic = 10\n",
    "\n",
    "    print(f\"---------------------Training {'GAN'}------------------------------\")\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.ToTensor(), # to (0 1)\n",
    "                        torchvision.transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]), # to (-1 1)\n",
    "                        torchvision.transforms.Resize((128,256))\n",
    "                        ])\n",
    "    vis_transform = torchvision.transforms.Compose([\n",
    "                                                    torchvision.transforms.Normalize([-1,-1,-1],[2,2,2])\n",
    "                                                    ])\n",
    "    dataset = KITTIdataset(transforms=transforms)\n",
    "    dataset_name = 'kitti'\n",
    "\n",
    "    # vis_transform = torchvision.transforms.Compose([\n",
    "    #                                                 torchvision.transforms.Normalize([-1,],[2,])\n",
    "    #                                                 ])\n",
    "\n",
    "\n",
    "    # dataset = torchvision.datasets.MNIST(r'F:\\COMP90055\\GMIDA\\datas\\MNIST_pytorch', train=True, download=True,\n",
    "    #                          transform=torchvision.transforms.Compose([\n",
    "    #                            torchvision.transforms.ToTensor(),\n",
    "    #                            torchvision.transforms.Resize((32,32)),\n",
    "    #                         #    torchvision.transforms.Normalize(\n",
    "    #                         #      (0.1307,), (0.3081,))\n",
    "    #                             torchvision.transforms.Normalize([0.5,],[0.5,])\n",
    "    #                          ]))\n",
    "    dataloader = DataLoader(dataset,\n",
    "                                  shuffle=True,\n",
    "                                  batch_size=batch_size,\n",
    "                                  num_workers=0,\n",
    "                                  pin_memory=False,\n",
    "                                  drop_last=True)\n",
    "    # dataset_name = 'mnist'\n",
    "    z_dim = 256\n",
    "    G = Generator(3,z_dim)\n",
    "    DG = Discriminator(3)\n",
    "    \n",
    "    G = torch.nn.DataParallel(G).cuda()\n",
    "    DG = torch.nn.DataParallel(DG).cuda()\n",
    "\n",
    "    dg_optimizer = torch.optim.Adam(DG.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "    g_optimizer = torch.optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "\n",
    "    step = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        for _,imgs,_ in tqdm(dataloader):\n",
    "            step += 1\n",
    "            imgs = imgs.cuda()\n",
    "            # plt.imshow(imgs[0].permute(1,2,0).cpu().numpy())\n",
    "            # plt.show()\n",
    "            b,c,h,w=imgs.size()\n",
    "            h = h//8\n",
    "            w = w//8\n",
    "            freeze(G)\n",
    "            unfreeze(DG)\n",
    "\n",
    "            z = torch.randn(b,z_dim,h,w).cuda() #latent vector\n",
    "            f_imgs = G(z)\n",
    "\n",
    "            r_logit = DG(imgs)\n",
    "            f_logit = DG(f_imgs)\n",
    "\n",
    "            wd = r_logit.mean() - f_logit.mean()  # Wasserstein-1 Distance\n",
    "            gp = gradient_penalty(DG,imgs.data, f_imgs.data)\n",
    "            dg_loss = - wd + gp * 10.0\n",
    "            \n",
    "            dg_optimizer.zero_grad()\n",
    "            dg_loss.backward()\n",
    "            dg_optimizer.step()\n",
    "\n",
    "            # train G\n",
    "\n",
    "            if step % n_critic == 0:\n",
    "                freeze(DG)\n",
    "                unfreeze(G)\n",
    "                z = torch.randn(b,z_dim,h,w).cuda()\n",
    "                f_imgs = G(z)\n",
    "                logit_dg = DG(f_imgs)\n",
    "                # calculate g_loss\n",
    "                g_loss = - logit_dg.mean()\n",
    "                \n",
    "                g_optimizer.zero_grad()\n",
    "                g_loss.backward()\n",
    "                g_optimizer.step()\n",
    "\n",
    "            if (step) % 100 == 0:\n",
    "                z = torch.randn(b,z_dim,h,w).cuda()\n",
    "                fake_image = G(z)\n",
    "                fake_image = vis_transform(fake_image)\n",
    "                grid = make_grid(fake_image,nrow=4)\n",
    "                writer.add_scalar(\"g_loss\",g_loss,step)\n",
    "                writer.add_scalar(\"dg_loss\",dg_loss,step) \n",
    "                writer.add_image(f'img_gt_pred', grid, step)\n",
    "                writer.add_scalar(\"Wasserstein_distance\",wd,step)\n",
    "                writer.add_scalar(\"gradient_penalty\",gp*10,step)\n",
    "\n",
    "        save_image(fake_image,os.path.join(save_img_dir,f\"{dataset_name}_gan_{step}.png\"))\n",
    "        end = time.time()\n",
    "        interval = end - start\n",
    "        print(\"Epoch:%d \\t Time:%.2f\" % (epoch, interval))\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            torch.save(G.state_dict(), os.path.join(save_model_dir, f\"{dataset_name}_{epoch}_G.pth\"))\n",
    "            torch.save(DG.state_dict(), os.path.join(save_model_dir, f\"{dataset_name}_{epoch}_D.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
